# 景点数据质量检查工具使用指南

## 概述

`check_data_quality.py` 是一个全面的数据质量检查工具，用于检测和改进国内城市景点数据的质量。

## 主要检查项目

### 1. 重复景点检测
- **名称相似度检测**：使用字符串相似度算法（阈值：80%）
- **坐标距离检测**：计算景点间实际距离（阈值：100米）
- 综合判断景点是否重复

### 2. 数据完整性检查
- 检查必填字段是否缺失
- 验证数据格式是否正确

### 3. 描述质量检查
- 检测空描述
- 检测过短描述（<50字符）
- 检测重复文本模板

### 4. 数据异常检测
- 评分越界检查（1-5分范围）
- 持续时间异常检查（<=0 或 >480分钟）
- 类别有效性检查

## 使用方法

### 1. 全面分析所有城市数据质量

```bash
python scripts/check_data_quality.py analyze
```

**输出内容**：
- 每个城市的景点数量和问题统计
- 重复景点清单
- 缺失字段详情
- 描述质量问题
- 数据异常详情
- 总体统计和改进建议

### 2. 查看重复景点报告

**所有城市**：
```bash
python scripts/check_data_quality.py duplicates
```

**特定城市**（如北京）：
```bash
python scripts/check_data_quality.py duplicates beijing
```

**输出内容**：
- 景点对比详情
- 名称相似度百分比
- 实际距离（米）
- 重复判断依据

### 3. 生成特定城市清理建议

```bash
python scripts/check_data_quality.py cleanup beijing
```

**输出内容**：
- 重复景点处理建议（带详细对比）
- 描述质量改进建议
- 具体的景点索引，便于定位

### 4. 导出重复景点报告为JSON

```bash
python scripts/check_data_quality.py export
```

**输出文件**：`output/duplicates_report.json`

这个JSON文件包含：
- 每个城市的重复景点详情
- 结构化数据，便于程序化处理
- 可用于批量修复工具

## 默认行为

如果不带任何参数运行，脚本会执行全面分析：

```bash
python scripts/check_data_quality.py
```

等同于 `python scripts/check_data_quality.py analyze`

## 输出示例

### 重复景点报告示例

```
📍 城市: beijing
   发现 28 组疑似重复景点

   1. 景点对比:
      景点A: 天安门 (索引: 1)
      景点B: 天安门-城楼 (索引: 12)
      名称相似度: 66.67%
      距离: 52 米
      判断依据: 距离 52米

   2. 景点对比:
      景点A: 故宫博物院-神武门 (索引: 20)
      景点B: 故宫博物院-神武门广场 (索引: 149)
      名称相似度: 75.00%
      距离: 20 米
      判断依据: 距离 20米
```

### 清理建议示例

```
🛠️ beijing 数据清理建议
================================================================================

1️⃣ 重复景点处理建议 (28 组):
--------------------------------------------------------------------------------

  组 1:
    景点A [1]: 天安门
      类别: sightseeing, 评分: 4.5
      描述长度: 120 字符
    景点B [12]: 天安门-城楼
      类别: history, 评分: 4.5
      描述长度: 95 字符
    建议: 位置非常接近，检查是否为同一景点的不同名称
```

## 检测阈值说明

可以在脚本中调整以下阈值参数：

- **名称相似度阈值**：`threshold_name=0.8`（80%）
  - 值越高，检测越严格
  - 建议范围：0.7-0.9

- **距离阈值**：`threshold_distance=100`（100米）
  - 值越小，检测越严格
  - 建议范围：50-200米

修改示例：
```python
duplicates = check_duplicate_spots(spots, city, threshold_name=0.85, threshold_distance=80)
```

## 数据修复建议

根据检查结果进行数据修复：

### 1. 处理重复景点

**判断标准**：
- 名称相似度 >90% 且距离 <50米 → **很可能重复，建议删除**
- 名称相似度 >80% → **疑似重复，需人工确认**
- 距离 <100米 → **可能是同一景点的子景点，需确认**

**处理方式**：
- **完全重复**：删除其中一个，保留信息更完整的
- **子景点**：考虑是否需要保留细节，或合并到主景点
- **不同景点**：如果确认是不同景点，保留两个

### 2. 完善缺失字段

```json
{
  "name": "景点名称",           // 必填
  "city": "beijing",          // 必填
  "category": "sightseeing",  // 必填
  "lat": 39.9042,            // 必填
  "lon": 116.4074,           // 必填
  "rating": 4.5,             // 必填，1-5
  "duration_minutes": 120,    // 必填，>0
  "description": "..."        // 必填，建议>50字符
}
```

### 3. 改进描述质量

- **空描述/过短描述**：补充详细的景点介绍
- **模板化描述**：使用更具体、个性化的描述
- **建议长度**：至少50个字符，最好100-200字符

## 批量修复工具

可以基于导出的JSON报告创建批量修复脚本：

```python
import json

# 读取报告
with open('output/duplicates_report.json', 'r', encoding='utf-8') as f:
    report = json.load(f)

# 处理每个城市的重复景点
for city, data in report.items():
    print(f"处理 {city}，发现 {data['duplicate_groups']} 组重复")
    # 根据具体规则自动或半自动处理
```

## 定期检查建议

建议在以下情况下运行数据质量检查：

1. **添加新景点数据后**
2. **批量更新数据后**
3. **部署到生产环境前**
4. **定期维护**（如每月一次）

## 常见问题

### Q: 为什么故宫内部的不同宫殿被标记为重复？

A: 因为它们距离很近（<100米）。如果这些是有价值的独立景点，可以保留。可以调整距离阈值或在名称中加入更多区分信息。

### Q: 如何处理"什刹海"和"什刹海-后海"这样的关系？

A: 这通常是主景点和子区域的关系。建议：
- 保留主景点（什刹海）
- 子区域可以作为独立景点，或在主景点描述中说明

### Q: 评分都是4.0是否有问题？

A: 如果所有景点评分都相同，可能是使用了默认值。建议使用真实的评分数据源（如大众点评、高德地图等）。

## 相关工具

- `scripts/validate_spots.py` - 基础验证工具
- `scripts/generate_ai_descriptions.py` - AI生成描述工具
- `scripts/enrich_spots_nearby.py` - 景点信息丰富化工具

## 反馈与改进

如果发现检测不准确或有改进建议，请：
1. 调整阈值参数
2. 修改`name_similarity`函数以适应更多场景
3. 添加更多自定义规则
