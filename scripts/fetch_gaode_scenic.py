#!/usr/bin/env python3
"""
é«˜å¾·åœ°å›¾ Web æœåŠ¡ API - æ™¯ç‚¹æ•°æ®é‡‡é›†è„šæœ¬
ä½¿ç”¨é«˜å¾·åœ°å›¾çš„ POI æœç´¢æœåŠ¡è·å–æ™¯ç‚¹ä¿¡æ¯
"""

import requests
import json
import time
import os
from pathlib import Path
from typing import List, Dict, Optional
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# ä»ç¯å¢ƒå˜é‡è·å– API Key
GAODE_API_KEY = os.getenv('GAODE_API_KEY')
if not GAODE_API_KEY:
    print("âŒ é”™è¯¯: GAODE_API_KEY ç¯å¢ƒå˜é‡æœªè®¾ç½®")
    print("è¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½® GAODE_API_KEYï¼Œæˆ–è¿è¡Œ:")
    print("export GAODE_API_KEY='your_actual_key'")
    exit(1)

API_URL = "https://restapi.amap.com/v3/place/text"

# åŸå¸‚åˆ—è¡¨ï¼ˆä¸­è‹±æ–‡å¯¹åº”ï¼‰
CITIES = {
    "beijing": "åŒ—äº¬",
    "shanghai": "ä¸Šæµ·",
    "guangzhou": "å¹¿å·",
    "shenzhen": "æ·±åœ³",
    "chengdu": "æˆéƒ½",
    "hangzhou": "æ­å·",
    "suzhou": "è‹å·",
    "nanjing": "å—äº¬",
    "qingdao": "é’å²›",
    "xiamen": "å¦é—¨",
    "wuhan": "æ­¦æ±‰",
    "xian": "è¥¿å®‰",
    "changchun": "é•¿æ˜¥",
    "harbin": "å“ˆå°”æ»¨",
    "shenyang": "æ²ˆé˜³",
    "taiyuan": "å¤ªåŸ",
    "lanzhou": "å…°å·",
    "xining": "è¥¿å®",
    "urumqi": "ä¹Œé²æœ¨é½",
    "kunming": "æ˜†æ˜",
    "guiyang": "è´µé˜³",
    "nanning": "å—å®",
    "fuzhou": "ç¦å·",
    "hefei": "åˆè‚¥",
    "zhengzhou": "éƒ‘å·",
    "jinan": "æµå—",
}

def fetch_scenic_data(city_name: str, page: int = 1) -> Optional[Dict]:
    """
    ä»é«˜å¾·åœ°å›¾ API è·å–æ™¯ç‚¹æ•°æ®
    
    Args:
        city_name: åŸå¸‚åç§°ï¼ˆä¸­æ–‡ï¼‰
        page: é¡µç ï¼ˆèµ·å§‹ 1ï¼‰
    
    Returns:
        API è¿”å›çš„ç»“æœæˆ– None
    """
    params = {
        'key': GAODE_API_KEY,
        'keywords': 'æ™¯ç‚¹',  # æœç´¢å…³é”®è¯
        'region': city_name,  # æŒ‡å®šåŸå¸‚
        'output': 'json',
        'pagesize': 50,  # æ¯é¡µæœ€å¤š 50 æ¡
        'page': page,
        'citylimit': True  # é™åˆ¶åœ¨æŒ‡å®šåŸå¸‚å†…
    }
    
    try:
        response = requests.get(API_URL, params=params, timeout=15)
        response.encoding = 'utf-8'
        data = response.json()
        
        if data.get('status') == '1':
            return data
        else:
            reason = data.get('info', 'Unknown error')
            print(f"    âŒ é«˜å¾· API é”™è¯¯: {reason}")
            return None
    except requests.exceptions.Timeout:
        print(f"    âŒ è¯·æ±‚è¶…æ—¶")
        return None
    except Exception as e:
        print(f"    âŒ è¯·æ±‚å¤±è´¥: {e}")
        return None

def convert_to_spot_format(poi_item: Dict, city_name: str) -> Dict:
    """
    å°†é«˜å¾·åœ°å›¾ POI æ ¼å¼è½¬æ¢ä¸ºæ ‡å‡† Spot æ ¼å¼
    
    Args:
        poi_item: é«˜å¾· POI é¡¹
        city_name: åŸå¸‚åç§°
    
    Returns:
        è½¬æ¢åçš„æ™¯ç‚¹æ•°æ®
    """
    name = poi_item.get('name', '').strip()
    
    # è·å–åæ ‡ï¼ˆæ ¼å¼ï¼šç»åº¦,çº¬åº¦ï¼‰
    location = poi_item.get('location', '')
    lat, lon = 0.0, 0.0
    if location and ',' in location:
        try:
            lon_str, lat_str = location.split(',')
            lat = float(lat_str)
            lon = float(lon_str)
        except:
            pass
    
    # è·å–åœ°å€å’Œç”µè¯ä½œä¸ºæè¿°
    address = poi_item.get('address', '')
    tel = poi_item.get('tel', '')
    type_info = poi_item.get('type', '')
    
    # æ„å»ºæè¿°
    description_parts = []
    if tel:
        description_parts.append(f"ç”µè¯: {tel}")
    if address:
        description_parts.append(f"åœ°å€: {address}")
    if type_info:
        description_parts.append(f"ç±»åˆ«: {type_info}")
    
    description = " | ".join(description_parts) if description_parts else f"ä½äº{city_name}çš„çŸ¥åæ™¯ç‚¹"
    
    # æ ¹æ®ç±»å‹æˆ–åç§°æ¨æ–­åˆ†ç±»
    category = "sightseeing"
    type_lower = type_info.lower() if type_info else ""
    name_lower = name.lower()
    
    if any(word in type_lower for word in ['åšç‰©é¦†', 'museum']):
        category = "museum"
    elif any(word in type_lower for word in ['å…¬å›­', 'park', 'æ£®æ—', 'forest', 'å±±', 'mountain']):
        category = "outdoor"
    elif any(word in type_lower for word in ['å¤åŸ', 'ancient', 'é—å€', 'ruins', 'å¤è¿¹', 'historic', 'çºªå¿µ', 'å®«', 'åº™', 'å¡”']):
        category = "history"
    elif any(word in name_lower for word in ['åšç‰©é¦†', 'ç¾æœ¯é¦†', 'çºªå¿µé¦†']):
        category = "museum"
    elif any(word in name_lower for word in ['å…¬å›­', 'å±±', 'æ¹–', 'æ±Ÿ', 'æµ·', 'æ£®æ—']):
        category = "outdoor"
    elif any(word in name_lower for word in ['å¤åŸ', 'å¤è¿¹', 'é—å€', 'å®«', 'åº™', 'å¡”', 'æ¡¥']):
        category = "history"
    
    # é»˜è®¤è¯„åˆ† 4.0
    rating = 4.0
    
    # é»˜è®¤è®¿é—®æ—¶é—´ 2 å°æ—¶
    duration_minutes = 120
    
    return {
        'name': name,
        'category': category,
        'duration_minutes': duration_minutes,
        'rating': rating,
        'lat': lat,
        'lon': lon,
        'description': description,
        'city': city_name,
    }

def fetch_city_spots(city_en: str, city_cn: str) -> List[Dict]:
    """
    è·å–åŸå¸‚çš„æ‰€æœ‰æ™¯ç‚¹
    
    Args:
        city_en: åŸå¸‚è‹±æ–‡å
        city_cn: åŸå¸‚ä¸­æ–‡å
    
    Returns:
        æ™¯ç‚¹åˆ—è¡¨
    """
    print(f"\næ­£åœ¨è·å– {city_cn} çš„æ™¯ç‚¹æ•°æ®...")
    
    all_spots = []
    page = 1
    max_pages = 50  # æœ€å¤šè·å– 50 é¡µï¼ˆ2500 æ¡æ™¯ç‚¹ï¼‰
    
    while page <= max_pages:
        print(f"  [ç¬¬ {page} é¡µ...]", end=' ', flush=True)
        
        result = fetch_scenic_data(city_cn, page=page)
        
        if not result:
            print("å¤±è´¥ï¼Œåœæ­¢")
            break
        
        pois = result.get('pois', [])
        if not pois:
            print("å®Œæˆï¼ˆæ— æ›´å¤šæ•°æ®ï¼‰")
            break
        
        print(f"{len(pois)} ä¸ªæ™¯ç‚¹", end='')
        
        # è½¬æ¢æ ¼å¼
        for poi in pois:
            spot = convert_to_spot_format(poi, city_cn)
            all_spots.append(spot)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ä¸‹ä¸€é¡µ
        count = result.get('count', '0')
        try:
            total = int(count)
            if len(all_spots) >= total:
                print(" âœ“ å…¨éƒ¨è·å–")
                break
            else:
                print()
        except:
            print()
        
        page += 1
        # é¿å… API é™æµ
        time.sleep(0.5)
    
    print(f"  âœ… å…±è·å¾— {len(all_spots)} ä¸ªæ™¯ç‚¹")
    return all_spots

def save_spots_to_file(city_en: str, spots: List[Dict]) -> bool:
    """
    å°†æ™¯ç‚¹æ•°æ®ä¿å­˜åˆ° JSON æ–‡ä»¶
    
    Args:
        city_en: åŸå¸‚è‹±æ–‡å
        spots: æ™¯ç‚¹åˆ—è¡¨
    
    Returns:
        æ˜¯å¦æˆåŠŸä¿å­˜
    """
    output_path = Path(f'data/spots_{city_en}.json')
    
    try:
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(spots, f, ensure_ascii=False, indent=2)
        return True
    except Exception as e:
        print(f"    âŒ ä¿å­˜æ–‡ä»¶å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 70)
    print("ğŸŒ é«˜å¾·åœ°å›¾ Web æœåŠ¡ API - æ™¯ç‚¹æ•°æ®é‡‡é›†")
    print("=" * 70)
    
    total_cities = len(CITIES)
    completed = 0
    successful = 0
    
    for city_en, city_cn in CITIES.items():
        completed += 1
        print(f"\n[{completed}/{total_cities}] å¤„ç† {city_cn}")
        
        # è·å–æ™¯ç‚¹æ•°æ®
        spots = fetch_city_spots(city_en, city_cn)
        
        if spots:
            # ä¿å­˜åˆ°æ–‡ä»¶
            if save_spots_to_file(city_en, spots):
                print(f"  ğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ° data/spots_{city_en}.json")
                successful += 1
            else:
                print(f"  âš ï¸ {city_cn} æ•°æ®è·å–æˆåŠŸï¼Œä½†ä¿å­˜å¤±è´¥")
        else:
            print(f"  âš ï¸ {city_cn} æœªè·å–åˆ°æ™¯ç‚¹æ•°æ®")
        
        # é¿å…è¿‡äºé¢‘ç¹çš„è¯·æ±‚
        if completed < total_cities:
            time.sleep(1)
    
    print("\n" + "=" * 70)
    print(f"âœ¨ æ•°æ®é‡‡é›†å®Œæˆï¼æˆåŠŸæ›´æ–° {successful}/{total_cities} ä¸ªåŸå¸‚")
    print("=" * 70)

if __name__ == '__main__':
    main()
